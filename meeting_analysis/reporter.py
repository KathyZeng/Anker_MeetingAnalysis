#!/usr/bin/env python3
"""
æŠ¥å‘Šç”Ÿæˆæ¨¡å—
ç”Ÿæˆå„ç±»æ ¼å¼çš„åˆ†ææŠ¥å‘Š(Markdown, HTML, PDFç­‰)
"""

import pandas as pd
from typing import Dict, List
from datetime import datetime
import os


class MeetingReportGenerator:
    """ä¼šè®®åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, output_dir: str = "output"):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

    def generate_executive_summary(self, kpi_results: Dict, filename: str = "executive_summary.md") -> str:
        """
        ç”Ÿæˆç®¡ç†å±‚æ‘˜è¦æŠ¥å‘Š

        Args:
            kpi_results: KPIè®¡ç®—ç»“æœ
            filename: æ–‡ä»¶å

        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        lines = []

        # æ ‡é¢˜
        lines.append("# ä¼šè®®æ”¹å–„æ•ˆæœè¯„ä¼° - ç®¡ç†å±‚æ‘˜è¦æŠ¥å‘Š")
        lines.append("")
        lines.append(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        lines.append("---")
        lines.append("")

        # æ ¸å¿ƒç»“è®º
        lines.append("## ğŸ“Š æ ¸å¿ƒç»“è®º")
        lines.append("")

        # ç»Ÿè®¡è¾¾æ ‡æƒ…å†µ
        primary_kpis = kpi_results.get('ä¸»è¦KPI', {})
        total_è¾¾æ ‡ = sum(1 for kpi in primary_kpis.values() if kpi.get('è¾¾æ ‡', False))
        total_count = len(primary_kpis)

        lines.append(f"**ä¸»è¦KPIè¾¾æ ‡æƒ…å†µ**: {total_è¾¾æ ‡}/{total_count} é¡¹è¾¾æ ‡")
        lines.append("")

        if total_è¾¾æ ‡ == total_count:
            lines.append("âœ… **è¯„ä¼°ç»“è®º**: ä¼šè®®æ”¹å–„æªæ–½æ•ˆæœæ˜¾è‘—,æ‰€æœ‰ä¸»è¦KPIå‡å·²è¾¾æ ‡!")
        elif total_è¾¾æ ‡ >= total_count / 2:
            lines.append("âš ï¸ **è¯„ä¼°ç»“è®º**: ä¼šè®®æ”¹å–„æªæ–½å–å¾—ä¸€å®šæˆæ•ˆ,éƒ¨åˆ†KPIå·²è¾¾æ ‡,ä»éœ€æŒç»­ä¼˜åŒ–")
        else:
            lines.append("âŒ **è¯„ä¼°ç»“è®º**: ä¼šè®®æ”¹å–„æ•ˆæœä¸æ˜æ˜¾,éœ€è¦é‡æ–°å®¡è§†æ”¹å–„æªæ–½å¹¶åŠ å¼ºæ‰§è¡Œ")

        lines.append("")
        lines.append("---")
        lines.append("")

        # ä¸»è¦KPIè¯¦æƒ…
        lines.append("## ğŸ¯ ä¸»è¦KPIæŒ‡æ ‡")
        lines.append("")

        for kpi_name, kpi_data in primary_kpis.items():
            è¾¾æ ‡ = kpi_data.get('è¾¾æ ‡', False)
            status_icon = "âœ…" if è¾¾æ ‡ else "âŒ"

            lines.append(f"### {status_icon} {kpi_name}")
            lines.append("")

            # åˆ›å»ºè¡¨æ ¼
            lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
            lines.append("|------|------|")

            for key, value in kpi_data.items():
                if key == 'è¾¾æ ‡':
                    continue
                if isinstance(value, float):
                    lines.append(f"| {key} | {value:.2f} |")
                else:
                    lines.append(f"| {key} | {value} |")

            lines.append("")

        # æ¬¡è¦KPIæ¦‚è§ˆ
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ“ˆ æ¬¡è¦KPIæ¦‚è§ˆ")
        lines.append("")

        secondary_kpis = kpi_results.get('æ¬¡è¦KPI', {})
        for kpi_name, kpi_data in secondary_kpis.items():
            è¾¾æ ‡ = kpi_data.get('è¾¾æ ‡', False)
            status_icon = "âœ…" if è¾¾æ ‡ else "âš ï¸"

            # æ„å»ºå®Œæ•´çš„è¡Œ
            line_text = f"- {status_icon} **{kpi_name}**: "

            # æå–å…³é”®å€¼
            if 'æ”¹å–„ç‡(%)' in kpi_data:
                line_text += f"æ”¹å–„ç‡ {kpi_data['æ”¹å–„ç‡(%)']:.1f}%"
            elif 'æ•ˆç‡æå‡(%)' in kpi_data:
                line_text += f"æ•ˆç‡æå‡ {kpi_data['æ•ˆç‡æå‡(%)']:.1f}%"
            elif 'æ›¿ä»£ç‡(%)' in kpi_data:
                line_text += f"æ›¿ä»£ç‡ {kpi_data['æ›¿ä»£ç‡(%)']:.1f}%"

            lines.append(line_text)
            lines.append("")

        # ç›‘æ§æŒ‡æ ‡
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ” ç›‘æ§æŒ‡æ ‡")
        lines.append("")

        monitoring = kpi_results.get('ç›‘æ§æŒ‡æ ‡', {})
        for indicator_name, indicator_data in monitoring.items():
            lines.append(f"### {indicator_name}")
            lines.append("")
            lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
            lines.append("|------|------|")

            for key, value in indicator_data.items():
                if isinstance(value, bool):
                    value_str = "âœ“ æ˜¯" if value else "âœ— å¦"
                elif isinstance(value, float):
                    value_str = f"{value:.2f}"
                else:
                    value_str = str(value)
                lines.append(f"| {key} | {value_str} |")

            lines.append("")

        # è¡ŒåŠ¨å»ºè®®
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ’¡ è¡ŒåŠ¨å»ºè®®")
        lines.append("")

        if total_è¾¾æ ‡ == total_count:
            lines.append("1. **å·©å›ºæˆæœ**: ç»§ç»­ä¿æŒå½“å‰çš„ä¼šè®®ç®¡ç†æœºåˆ¶,é¿å…åå¼¹")
            lines.append("2. **ç»éªŒæ€»ç»“**: æ€»ç»“å›ºå®šä¼šè®®çª—å£ç­‰æœ‰æ•ˆæªæ–½,å½¢æˆæœ€ä½³å®è·µ")
            lines.append("3. **æŒç»­ç›‘æ§**: ä¿æŒæ¯å‘¨ç›‘æ§,å…³æ³¨æ³¢åŠ¨æ€§æŒ‡æ ‡")
        else:
            lines.append("1. **é‡ç‚¹æ”¹è¿›**: é’ˆå¯¹æœªè¾¾æ ‡çš„KPIåˆ¶å®šä¸“é¡¹æ”¹å–„è®¡åˆ’")
            lines.append("2. **å¼ºåŒ–æ‰§è¡Œ**: åŠ å¼ºå¯¹å›ºå®šä¼šè®®çª—å£åˆ¶åº¦çš„å®£è´¯å’Œæ‰§è¡Œç›‘ç£")
            lines.append("3. **ä¸ªæ€§åŒ–è¾…å¯¼**: é’ˆå¯¹Top 10é‡åº¦ä¼šè®®ç”¨æˆ·è¿›è¡Œä¸€å¯¹ä¸€è¾…å¯¼")
            lines.append("4. **å·¥å…·ä¼˜åŒ–**: è¯„ä¼°æ˜¯å¦éœ€è¦ä¼˜åŒ–æ—¥ç¨‹ç®¡ç†å·¥å…·å’Œä¼šè®®å®¤é¢„è®¢æµç¨‹")

        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("*æœ¬æŠ¥å‘Šç”±ä¼šè®®åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*")

        # ä¿å­˜æŠ¥å‘Š
        content = '\n'.join(lines)
        filepath = os.path.join(self.output_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)

        return filepath

    def generate_detailed_report(self, kpi_results: Dict, trend_analysis: Dict,
                                anomalies: pd.DataFrame, top_users: pd.DataFrame,
                                filename: str = "detailed_report.md") -> str:
        """
        ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š

        Args:
            kpi_results: KPIç»“æœ
            trend_analysis: è¶‹åŠ¿åˆ†æç»“æœ
            anomalies: å¼‚å¸¸æ•°æ®
            top_users: Topç”¨æˆ·æ•°æ®
            filename: æ–‡ä»¶å

        Returns:
            str: æ–‡ä»¶è·¯å¾„
        """
        lines = []

        # æ ‡é¢˜
        lines.append("# ä¼šè®®æ”¹å–„æ•ˆæœè¯„ä¼° - è¯¦ç»†åˆ†ææŠ¥å‘Š")
        lines.append("")
        lines.append(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        lines.append("---")
        lines.append("")

        # ç›®å½•
        lines.append("## ğŸ“‘ ç›®å½•")
        lines.append("")
        lines.append("1. [KPIæŒ‡æ ‡è¯¦æƒ…](#kpiæŒ‡æ ‡è¯¦æƒ…)")
        lines.append("2. [è¶‹åŠ¿åˆ†æ](#è¶‹åŠ¿åˆ†æ)")
        lines.append("3. [å¼‚å¸¸æ£€æµ‹](#å¼‚å¸¸æ£€æµ‹)")
        lines.append("4. [Topç”¨æˆ·åˆ†æ](#topç”¨æˆ·åˆ†æ)")
        lines.append("5. [æ”¹å–„å»ºè®®](#æ”¹å–„å»ºè®®)")
        lines.append("")
        lines.append("---")
        lines.append("")

        # 1. KPIæŒ‡æ ‡è¯¦æƒ…
        lines.append("## KPIæŒ‡æ ‡è¯¦æƒ…")
        lines.append("")

        lines.append("### ä¸»è¦KPI")
        lines.append("")
        for kpi_name, kpi_data in kpi_results.get('ä¸»è¦KPI', {}).items():
            lines.append(f"#### {kpi_name}")
            lines.append("")
            lines.append("```")
            for key, value in kpi_data.items():
                if isinstance(value, float):
                    lines.append(f"{key:30s}: {value:>10.2f}")
                elif isinstance(value, bool):
                    lines.append(f"{key:30s}: {('âœ“ æ˜¯' if value else 'âœ— å¦'):>10s}")
                else:
                    lines.append(f"{key:30s}: {str(value):>10s}")
            lines.append("```")
            lines.append("")

        lines.append("### æ¬¡è¦KPI")
        lines.append("")
        for kpi_name, kpi_data in kpi_results.get('æ¬¡è¦KPI', {}).items():
            lines.append(f"#### {kpi_name}")
            lines.append("")
            lines.append("```")
            for key, value in kpi_data.items():
                if isinstance(value, float):
                    lines.append(f"{key:30s}: {value:>10.2f}")
                elif isinstance(value, bool):
                    lines.append(f"{key:30s}: {('âœ“ æ˜¯' if value else 'âœ— å¦'):>10s}")
                else:
                    lines.append(f"{key:30s}: {str(value):>10s}")
            lines.append("```")
            lines.append("")

        # 2. è¶‹åŠ¿åˆ†æ
        lines.append("---")
        lines.append("")
        lines.append("## è¶‹åŠ¿åˆ†æ")
        lines.append("")

        for metric_name, trend_data in trend_analysis.items():
            if 'error' in trend_data:
                continue

            lines.append(f"### {metric_name}")
            lines.append("")
            lines.append(f"- **è¶‹åŠ¿æ–¹å‘**: {trend_data.get('direction', 'unknown')}")
            lines.append(f"- **å˜åŒ–ç‡**: {trend_data.get('change_rate', 0):.2f}%")
            lines.append(f"- **RÂ² æ‹Ÿåˆåº¦**: {trend_data.get('r_squared', 0):.4f}")
            lines.append(f"- **èµ·å§‹å€¼**: {trend_data.get('first_value', 0):.2f}")
            lines.append(f"- **ç»“æŸå€¼**: {trend_data.get('last_value', 0):.2f}")
            lines.append("")

        # 3. å¼‚å¸¸æ£€æµ‹
        lines.append("---")
        lines.append("")
        lines.append("## å¼‚å¸¸æ£€æµ‹")
        lines.append("")

        if anomalies is not None and not anomalies.empty:
            lines.append(f"æ£€æµ‹åˆ° **{len(anomalies)}** ä¸ªå¼‚å¸¸æ•°æ®ç‚¹:")
            lines.append("")
            lines.append(anomalies.to_markdown(index=False))
        else:
            lines.append("âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾å¼‚å¸¸")

        lines.append("")

        # 4. Topç”¨æˆ·åˆ†æ
        lines.append("---")
        lines.append("")
        lines.append("## Topç”¨æˆ·åˆ†æ")
        lines.append("")

        if top_users is not None and not top_users.empty:
            lines.append("### Top 10 ä¼šè®®æœ€å¤šçš„ç”¨æˆ·")
            lines.append("")
            lines.append(top_users.to_markdown(index=False))
            lines.append("")
        else:
            lines.append("æ— æ•°æ®")
            lines.append("")

        # 5. æ”¹å–„å»ºè®®
        lines.append("---")
        lines.append("")
        lines.append("## æ”¹å–„å»ºè®®")
        lines.append("")

        # åŸºäºKPIè¾¾æ ‡æƒ…å†µç”Ÿæˆå»ºè®®
        primary_kpis = kpi_results.get('ä¸»è¦KPI', {})
        æœªè¾¾æ ‡_kpis = [name for name, data in primary_kpis.items() if not data.get('è¾¾æ ‡', False)]

        if not æœªè¾¾æ ‡_kpis:
            lines.append("### âœ… æ•´ä½“è¡¨ç°ä¼˜ç§€")
            lines.append("")
            lines.append("æ‰€æœ‰ä¸»è¦KPIå‡å·²è¾¾æ ‡,å»ºè®®:")
            lines.append("")
            lines.append("1. ç»§ç»­ä¿æŒå½“å‰çš„ä¼šè®®ç®¡ç†å®è·µ")
            lines.append("2. å®šæœŸç›‘æ§æ³¢åŠ¨æ€§,é˜²æ­¢åå¼¹")
            lines.append("3. å°†æˆåŠŸç»éªŒæ¨å¹¿åˆ°å…¶ä»–å›¢é˜Ÿ")
        else:
            lines.append("### âš ï¸ éœ€è¦é‡ç‚¹æ”¹è¿›çš„é¢†åŸŸ")
            lines.append("")
            for kpi_name in æœªè¾¾æ ‡_kpis:
                lines.append(f"#### {kpi_name}")
                lines.append("")

                if "ä¼šè®®æ•°" in kpi_name:
                    lines.append("**å»ºè®®æªæ–½**:")
                    lines.append("- ä¸¥æ ¼æ‰§è¡Œä¼šè®®å®¡æ‰¹åˆ¶åº¦")
                    lines.append("- æ¨å¹¿å¼‚æ­¥æ²Ÿé€šå·¥å…·ä½¿ç”¨")
                    lines.append("- ä¼˜åŒ–ä¼šè®®é‚€è¯·äººå‘˜èŒƒå›´")
                elif "ä¼šè®®æ—¶é•¿" in kpi_name:
                    lines.append("**å»ºè®®æªæ–½**:")
                    lines.append("- å¼ºåˆ¶è¦æ±‚ä¼šè®®è®¾ç½®æ˜ç¡®è®®ç¨‹")
                    lines.append("- æ¨è¡Œ30åˆ†é’Ÿå’Œ45åˆ†é’Ÿæ ‡å‡†ä¼šè®®æ—¶é•¿")
                    lines.append("- åŸ¹è®­ä¸»æŒäººä¼šè®®ç®¡ç†æŠ€å·§")
                elif "å³æ—¶ä¼šè®®" in kpi_name:
                    lines.append("**å»ºè®®æªæ–½**:")
                    lines.append("- åŠ å¼ºæ—¥ç¨‹ç®¡ç†åŸ¹è®­")
                    lines.append("- è¦æ±‚æå‰24å°æ—¶å®‰æ’ä¼šè®®")
                    lines.append("- é™åˆ¶å³æ—¶ä¼šè®®å‘èµ·æƒé™")

                lines.append("")

        lines.append("---")
        lines.append("")
        lines.append("*æœ¬æŠ¥å‘Šç”±ä¼šè®®åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*")

        # ä¿å­˜æŠ¥å‘Š
        content = '\n'.join(lines)
        filepath = os.path.join(self.output_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)

        return filepath

    def generate_personal_report(self, user_data: pd.DataFrame, user_name: str,
                                 team_avg: Dict, filename: str = None) -> str:
        """
        ç”Ÿæˆä¸ªäººä¼šè®®å¥åº·æŠ¥å‘Š

        Args:
            user_data: ç”¨æˆ·æ•°æ®
            user_name: ç”¨æˆ·å
            team_avg: å›¢é˜Ÿå¹³å‡æ•°æ®
            filename: æ–‡ä»¶å

        Returns:
            str: æ–‡ä»¶è·¯å¾„
        """
        if filename is None:
            filename = f"personal_report_{user_name}.md"

        lines = []

        # æ ‡é¢˜
        lines.append(f"# ä¸ªäººä¼šè®®å¥åº·æŠ¥å‘Š - {user_name}")
        lines.append("")
        lines.append(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        lines.append("---")
        lines.append("")

        # ä¸ªäººæ•°æ®æ¦‚è§ˆ
        lines.append("## ğŸ“Š ä¸ªäººæ•°æ®æ¦‚è§ˆ")
        lines.append("")

        if not user_data.empty:
            avg_meetings = user_data['æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°'].mean()
            avg_duration = user_data['æ—¥äººå‡çº¿ä¸Šä¼šè®®æ—¶é•¿(åˆ†é’Ÿ)'].mean()

            lines.append("| æŒ‡æ ‡ | ä¸ªäººå‡å€¼ | å›¢é˜Ÿå‡å€¼ | å¯¹æ¯” |")
            lines.append("|------|---------|---------|------|")

            # ä¼šè®®æ•°å¯¹æ¯”
            team_meetings = team_avg.get('æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°', avg_meetings)
            diff_meetings = ((avg_meetings - team_meetings) / team_meetings * 100) if team_meetings > 0 else 0
            trend_icon = "â¬‡ï¸" if avg_meetings < team_meetings else "â¬†ï¸"
            lines.append(f"| æ—¥äººå‡ä¼šè®®æ•° | {avg_meetings:.2f} | {team_meetings:.2f} | {trend_icon} {diff_meetings:+.1f}% |")

            # æ—¶é•¿å¯¹æ¯”
            team_duration = team_avg.get('æ—¥äººå‡çº¿ä¸Šä¼šè®®æ—¶é•¿(åˆ†é’Ÿ)', avg_duration)
            diff_duration = ((avg_duration - team_duration) / team_duration * 100) if team_duration > 0 else 0
            trend_icon = "â¬‡ï¸" if avg_duration < team_duration else "â¬†ï¸"
            lines.append(f"| æ—¥äººå‡ä¼šè®®æ—¶é•¿ | {avg_duration:.2f} | {team_duration:.2f} | {trend_icon} {diff_duration:+.1f}% |")

            lines.append("")

        # è¶‹åŠ¿åˆ†æ
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ“ˆ ä¸ªäººè¶‹åŠ¿")
        lines.append("")

        if not user_data.empty and 'period_name' in user_data.columns:
            trend_data = user_data.groupby('period_name')['æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°'].mean().reset_index()

            lines.append("### ä¼šè®®æ•°å˜åŒ–è¶‹åŠ¿")
            lines.append("")
            lines.append("| å‘¨æœŸ | æ—¥äººå‡ä¼šè®®æ•° |")
            lines.append("|------|-------------|")

            for _, row in trend_data.iterrows():
                lines.append(f"| {row['period_name']} | {row['æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°']:.2f} |")

            lines.append("")

        # å¥åº·å»ºè®®
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ’¡ å¥åº·å»ºè®®")
        lines.append("")

        if not user_data.empty:
            if avg_meetings > team_meetings * 1.2:
                lines.append("### âš ï¸ ä¼šè®®è´Ÿæ‹…è¾ƒé‡")
                lines.append("")
                lines.append("æ‚¨çš„ä¼šè®®æ•°é‡æ˜æ˜¾é«˜äºå›¢é˜Ÿå¹³å‡æ°´å¹³,å»ºè®®:")
                lines.append("")
                lines.append("1. å®¡æŸ¥æ—¥å†,è¯†åˆ«å¯ä»¥æ‹’ç»æˆ–å§”æ‰˜ä»–äººå‚åŠ çš„ä¼šè®®")
                lines.append("2. ä¸ä¸»ç®¡è®¨è®ºä¼˜å…ˆçº§,èšç„¦æ ¸å¿ƒå·¥ä½œ")
                lines.append("3. å°è¯•å°†éƒ¨åˆ†ä¼šè®®æ”¹ä¸ºå¼‚æ­¥æ²Ÿé€š")
                lines.append("")
            elif avg_meetings < team_meetings * 0.8:
                lines.append("### âœ… ä¼šè®®ç®¡ç†è‰¯å¥½")
                lines.append("")
                lines.append("æ‚¨çš„ä¼šè®®æ•°é‡æ§åˆ¶å¾—å¾ˆå¥½,ä½äºå›¢é˜Ÿå¹³å‡æ°´å¹³ã€‚")
                lines.append("")
            else:
                lines.append("### âœ… ä¼šè®®è´Ÿæ‹…é€‚ä¸­")
                lines.append("")
                lines.append("æ‚¨çš„ä¼šè®®æ•°é‡å¤„äºå¥åº·èŒƒå›´å†…ã€‚")
                lines.append("")

        lines.append("---")
        lines.append("")
        lines.append("*æœ¬æŠ¥å‘Šç”±ä¼šè®®åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ,ä»…ä¾›ä¸ªäººå‚è€ƒ*")

        # ä¿å­˜æŠ¥å‘Š
        content = '\n'.join(lines)
        filepath = os.path.join(self.output_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)

        return filepath

    def generate_weekly_summary(self, week_data: pd.DataFrame, week_name: str,
                               filename: str = None) -> str:
        """
        ç”Ÿæˆå‘¨æŠ¥

        Args:
            week_data: æœ¬å‘¨æ•°æ®
            week_name: å‘¨æœŸåç§°
            filename: æ–‡ä»¶å

        Returns:
            str: æ–‡ä»¶è·¯å¾„
        """
        if filename is None:
            filename = f"weekly_summary_{week_name}.md"

        lines = []

        # æ ‡é¢˜
        lines.append(f"# ä¼šè®®æ•°æ®å‘¨æŠ¥ - {week_name}")
        lines.append("")
        lines.append(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        lines.append("---")
        lines.append("")

        # æœ¬å‘¨æ¦‚è§ˆ
        lines.append("## ğŸ“Š æœ¬å‘¨æ¦‚è§ˆ")
        lines.append("")

        if not week_data.empty:
            total_records = len(week_data)
            avg_meetings = week_data['æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°'].mean()
            avg_duration = week_data['æ—¥äººå‡çº¿ä¸Šä¼šè®®æ—¶é•¿(åˆ†é’Ÿ)'].mean()

            lines.append(f"- **æ•°æ®è®°å½•æ•°**: {total_records}")
            lines.append(f"- **æ—¥äººå‡ä¼šè®®æ•°**: {avg_meetings:.2f}")
            lines.append(f"- **æ—¥äººå‡ä¼šè®®æ—¶é•¿**: {avg_duration:.2f} åˆ†é’Ÿ")
            lines.append("")

        # Top 10 ç”¨æˆ·
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ‘¥ Top 10 ä¼šè®®æœ€å¤šçš„ç”¨æˆ·")
        lines.append("")

        if not week_data.empty and 'user_name' in week_data.columns:
            top10 = week_data.nlargest(10, 'æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°')[['user_name', 'æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°', 'æ—¥äººå‡çº¿ä¸Šä¼šè®®æ—¶é•¿(åˆ†é’Ÿ)']]
            lines.append(top10.to_markdown(index=False))
        else:
            lines.append("æ— æ•°æ®")

        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("*æœ¬å‘¨æŠ¥ç”±ä¼šè®®åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*")

        # ä¿å­˜æŠ¥å‘Š
        content = '\n'.join(lines)
        filepath = os.path.join(self.output_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)

        return filepath


def test_reporter():
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""
    print("=" * 60)
    print("æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨")
    print("=" * 60)

    from data_loader import MeetingDataLoader
    from calculator import MeetingMetricsCalculator
    from analyzer import MeetingDataAnalyzer

    # åŠ è½½æ•°æ®
    loader = MeetingDataLoader()
    data = loader.load_all_data()

    if data is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        return

    # è·å–åŸºçº¿æœŸå’Œå½“å‰æœŸæ•°æ®
    baseline = loader.get_baseline_data()
    current = loader.get_recent_weeks_data(4)

    # è®¡ç®—KPI
    calculator = MeetingMetricsCalculator(baseline, current)
    kpi_results = calculator.calculate_all_kpis(loader.get_data_by_period_type('weekly'))

    # åˆ›å»ºåˆ†æå™¨
    analyzer = MeetingDataAnalyzer(data)

    # è¶‹åŠ¿åˆ†æ
    trend_analysis = {
        'æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°': analyzer.analyze_trend('æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°'),
        'æ—¥äººå‡çº¿ä¸Šä¼šè®®æ—¶é•¿': analyzer.analyze_trend('æ—¥äººå‡çº¿ä¸Šä¼šè®®æ—¶é•¿(åˆ†é’Ÿ)')
    }

    # å¼‚å¸¸æ£€æµ‹
    anomalies = analyzer.detect_anomalies('æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°', threshold=2.0)

    # Topç”¨æˆ·
    top_users = analyzer.identify_top_users('æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°', n=10)

    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    reporter = MeetingReportGenerator()

    # 1. ç”Ÿæˆç®¡ç†å±‚æ‘˜è¦
    print("\nç”Ÿæˆç®¡ç†å±‚æ‘˜è¦æŠ¥å‘Š...")
    exec_report = reporter.generate_executive_summary(kpi_results)
    print(f"âœ“ å·²ä¿å­˜: {exec_report}")

    # 2. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    print("\nç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š...")
    detail_report = reporter.generate_detailed_report(
        kpi_results,
        trend_analysis,
        anomalies,
        top_users
    )
    print(f"âœ“ å·²ä¿å­˜: {detail_report}")

    # 3. ç”Ÿæˆä¸ªäººæŠ¥å‘Šç¤ºä¾‹
    if 'user_name' in data.columns and len(data) > 0:
        print("\nç”Ÿæˆä¸ªäººæŠ¥å‘Šç¤ºä¾‹...")
        sample_user = data['user_name'].iloc[0]
        user_data = data[data['user_name'] == sample_user]
        team_avg = {
            'æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°': data['æ—¥äººå‡çº¿ä¸Šä¼šè®®æ•°'].mean(),
            'æ—¥äººå‡çº¿ä¸Šä¼šè®®æ—¶é•¿(åˆ†é’Ÿ)': data['æ—¥äººå‡çº¿ä¸Šä¼šè®®æ—¶é•¿(åˆ†é’Ÿ)'].mean()
        }
        personal_report = reporter.generate_personal_report(user_data, sample_user, team_avg)
        print(f"âœ“ å·²ä¿å­˜: {personal_report}")

    # 4. ç”Ÿæˆå‘¨æŠ¥ç¤ºä¾‹
    print("\nç”Ÿæˆå‘¨æŠ¥ç¤ºä¾‹...")
    periods = loader.get_period_list()
    if periods:
        latest_period = periods[-1]['period_name']
        week_data = loader.get_data_by_period(latest_period)
        weekly_report = reporter.generate_weekly_summary(week_data, latest_period)
        print(f"âœ“ å·²ä¿å­˜: {weekly_report}")

    print("\nâœ… æŠ¥å‘Šç”Ÿæˆæµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_reporter()
